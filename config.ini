[STANDARD]
path_dataset = dataset02/

# alternative is to train from scratch using the best parameters from gridsearch
use_pretrained_classifier = False

# specify where trained classifiers should be saved to
path_trained_classifier = trained_classifiers/

# specify where best parameters should be saved to
path_best_params = classifiers_best_params/

# 0 means to use all samples
num_samples = 0

[DATASET]
# training testing data
# shortcuts:

# will take the whole dataset and split it 2/3 to 1/3
normal_evaluation = False

training = None
testing = None
#training = without ambiguous
#training = only ambiguous
#testing = without ambiguous
#testing = only ambiguous

### manual split
# define how to split the data categories among train and test
# e.g. only 30% of ambigous samples should go into train, the remaining 70% into test
# => ambiguous_train_test = 0.3, 0.7
# it does not have to add up to 1 but max is 1, can be 0
vanilla_train_part = 0.8
vanilla_test_part = 0.2

ambiguous_train_part = 0.5
ambiguous_test_part = 0.5

overlap_train_part = 0.7
overlap_test_part = 0.3

both_train_part = 0.7
both_test_part = 0.3


[GRID_SEARCH]
Nearest_Neighbors = {'n_neighbors': [2, 5, 10], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'brute']}
Linear_SVM = {'kernel':['linear'], 'C': [1, 5, 10], 'probability': [True], 'random_state':[17, 42]}
RBF_SVM = {'kernel':['rbf'], 'C':[1, 5, 10], 'probability': [True], 'random_state':[17, 42]}
Gaussian_Process = {'random_state':[17, 42]}
Decision_Tree = {'max_depth':[None, 5, 10], 'min_samples_split': [2, 5, 10], 'random_state':[17, 42]}
Random_Forest = {'max_depth':[None, 5, 10], 'n_estimators':[10, 50, 100], 'max_features':[1], 'random_state':[17, 42]}
Neural_Net = {'alpha': [0.0001, 0.001], 'max_iter': [1000, 2000], 'random_state':[17, 42]}
Naive_Bayes = {}
QDA = {'reg_param': [0.0, 0.5],'tol': [1.0e-2, 1.0e-4, 1.0e-6]}
Glvq = {'max_prototypes_per_class':[5], 'learning_rate':[5], 'strech_factor':[1]}
